{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wybór modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie funkcji i zbiorów danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn()\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "#from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, SelectFromModel, RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, precision_score, recall_score, roc_curve, auc\n",
    "#from category_encoders import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets(df, with_tests = 0): \n",
    "    y = np.array(df.is_canceled)\n",
    "    X = df.drop(['is_canceled'], axis=1)\n",
    "    #X.is_canceled\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=42\n",
    "    ) \n",
    "    #stratify - podział zbioru y, żeby był zrównoważony\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train, y_train, stratify=y_train, test_size=0.25, random_state=42 # 0.25 * 0.8 = 0.2\n",
    "    )\n",
    "    #print(X_val)\n",
    "    X_train_val=pd.concat((X_train,X_val))\n",
    "    y_train_val=np.concatenate((y_train,y_val), axis=0)\n",
    "    print(X_train.shape, X_val.shape, X_test.shape)\n",
    "    if with_tests: return X_train, X_val, y_train, y_val, X_train_val, y_train_val, X_test, y_test\n",
    "    return X_train, X_val, y_train, y_val, X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"hotel_bookings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Przygotowanie ramki do modelu** - stworzenie i wybór zmiennych na podstawie wniosków z wcześniejszych etapów projektu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_temp = df_raw.copy()\n",
    "df_raw_temp['lead_time_std'] = -1.0\n",
    "df_raw_temp.loc[df_raw_temp['lead_time'] > 0, 'lead_time_std'] = np.log(df_raw_temp.lead_time[df_raw_temp.lead_time > 0])\n",
    "df_raw_temp['lead_time_std'] = (df_raw_temp['lead_time_std'] - np.mean(df_raw_temp['lead_time_std']))/np.std(df_raw_temp['lead_time_std'])\n",
    "\n",
    "df_raw_temp['is_reserved_compatible'] = (df_raw_temp['assigned_room_type'] == df_raw_temp['reserved_room_type']).astype(int)\n",
    "df_raw_temp[\"cancelations_proportion\"] = df_raw_temp.apply(\n",
    "    lambda row: 0.5 if row[\"is_repeated_guest\"] == 0 else row[\"previous_cancellations\"] / \n",
    "    (row[\"previous_cancellations\"] + row[\"previous_bookings_not_canceled\"]) \n",
    "    if (row[\"previous_cancellations\"] + row[\"previous_bookings_not_canceled\"]) > 0 else 0.5,\n",
    "    axis=1\n",
    ")\n",
    "df_raw_en = pd.get_dummies(df_raw_temp, columns= df_raw_temp.drop(['market_segment'], axis = 1).select_dtypes(include=['object']).columns.to_list(), dtype='int')\n",
    "df = df_raw_en.drop_duplicates().loc[\n",
    "    :, ['is_canceled', 'required_car_parking_spaces', 'lead_time_std', 'is_reserved_compatible', 'total_of_special_requests', \n",
    "        'deposit_type_Non Refund', 'adr', 'cancelations_proportion', 'customer_type_Transient', 'country_PRT', 'previous_cancellations',\n",
    "        'previous_bookings_not_canceled', 'hotel_Resort Hotel', 'country_GBR', 'country_FRA', 'market_segment']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>lead_time_std</th>\n",
       "      <th>is_reserved_compatible</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>deposit_type_Non Refund</th>\n",
       "      <th>adr</th>\n",
       "      <th>cancelations_proportion</th>\n",
       "      <th>customer_type_Transient</th>\n",
       "      <th>country_PRT</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <th>hotel_Resort Hotel</th>\n",
       "      <th>country_GBR</th>\n",
       "      <th>country_FRA</th>\n",
       "      <th>market_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.159231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.581944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.981870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.641047</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.600246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119385</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.326924</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.14</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Offline TA/TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493134</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>225.43</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119387</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.111726</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>157.71</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119388</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104.40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.877451</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>151.20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87396 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_canceled  required_car_parking_spaces  lead_time_std  \\\n",
       "0                 0                            0       1.159231   \n",
       "1                 0                            0       1.581944   \n",
       "2                 0                            0      -0.981870   \n",
       "3                 0                            0      -0.641047   \n",
       "4                 0                            0      -0.600246   \n",
       "...             ...                          ...            ...   \n",
       "119385            0                            0      -0.326924   \n",
       "119386            0                            0       0.493134   \n",
       "119387            0                            0      -0.111726   \n",
       "119388            0                            0       0.529678   \n",
       "119389            0                            0       0.877451   \n",
       "\n",
       "        is_reserved_compatible  total_of_special_requests  \\\n",
       "0                            1                          0   \n",
       "1                            1                          0   \n",
       "2                            0                          0   \n",
       "3                            1                          0   \n",
       "4                            1                          1   \n",
       "...                        ...                        ...   \n",
       "119385                       1                          0   \n",
       "119386                       1                          2   \n",
       "119387                       1                          4   \n",
       "119388                       1                          0   \n",
       "119389                       1                          2   \n",
       "\n",
       "        deposit_type_Non Refund     adr  cancelations_proportion  \\\n",
       "0                             0    0.00                      0.5   \n",
       "1                             0    0.00                      0.5   \n",
       "2                             0   75.00                      0.5   \n",
       "3                             0   75.00                      0.5   \n",
       "4                             0   98.00                      0.5   \n",
       "...                         ...     ...                      ...   \n",
       "119385                        0   96.14                      0.5   \n",
       "119386                        0  225.43                      0.5   \n",
       "119387                        0  157.71                      0.5   \n",
       "119388                        0  104.40                      0.5   \n",
       "119389                        0  151.20                      0.5   \n",
       "\n",
       "        customer_type_Transient  country_PRT  previous_cancellations  \\\n",
       "0                             1            1                       0   \n",
       "1                             1            1                       0   \n",
       "2                             1            0                       0   \n",
       "3                             1            0                       0   \n",
       "4                             1            0                       0   \n",
       "...                         ...          ...                     ...   \n",
       "119385                        1            0                       0   \n",
       "119386                        1            0                       0   \n",
       "119387                        1            0                       0   \n",
       "119388                        1            0                       0   \n",
       "119389                        1            0                       0   \n",
       "\n",
       "        previous_bookings_not_canceled  hotel_Resort Hotel  country_GBR  \\\n",
       "0                                    0                   1            0   \n",
       "1                                    0                   1            0   \n",
       "2                                    0                   1            1   \n",
       "3                                    0                   1            1   \n",
       "4                                    0                   1            1   \n",
       "...                                ...                 ...          ...   \n",
       "119385                               0                   0            0   \n",
       "119386                               0                   0            0   \n",
       "119387                               0                   0            0   \n",
       "119388                               0                   0            1   \n",
       "119389                               0                   0            0   \n",
       "\n",
       "        country_FRA market_segment  \n",
       "0                 0         Direct  \n",
       "1                 0         Direct  \n",
       "2                 0         Direct  \n",
       "3                 0      Corporate  \n",
       "4                 0      Online TA  \n",
       "...             ...            ...  \n",
       "119385            0  Offline TA/TO  \n",
       "119386            1      Online TA  \n",
       "119387            0      Online TA  \n",
       "119388            0      Online TA  \n",
       "119389            0      Online TA  \n",
       "\n",
       "[87396 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52437, 15) (17480, 15) (17479, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>lead_time_std</th>\n",
       "      <th>is_reserved_compatible</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>deposit_type_Non Refund</th>\n",
       "      <th>adr</th>\n",
       "      <th>cancelations_proportion</th>\n",
       "      <th>customer_type_Transient</th>\n",
       "      <th>country_PRT</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <th>hotel_Resort Hotel</th>\n",
       "      <th>country_GBR</th>\n",
       "      <th>country_FRA</th>\n",
       "      <th>market_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14374</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.167121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66734</th>\n",
       "      <td>0</td>\n",
       "      <td>0.529678</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>97.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>0</td>\n",
       "      <td>0.861096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.603792</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8552</th>\n",
       "      <td>1</td>\n",
       "      <td>1.221569</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86997</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.167121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97719</th>\n",
       "      <td>0</td>\n",
       "      <td>0.316453</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102.68</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Offline TA/TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112300</th>\n",
       "      <td>0</td>\n",
       "      <td>0.293668</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17700</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.603792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16019</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.603792</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>154.80</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Online TA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52437 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        required_car_parking_spaces  lead_time_std  is_reserved_compatible  \\\n",
       "14374                             0      -1.167121                       1   \n",
       "66734                             0       0.529678                       1   \n",
       "7371                              0       0.861096                       1   \n",
       "13898                             1      -2.603792                       0   \n",
       "8552                              1       1.221569                       1   \n",
       "...                             ...            ...                     ...   \n",
       "86997                             0      -1.167121                       1   \n",
       "97719                             0       0.316453                       1   \n",
       "112300                            0       0.293668                       1   \n",
       "17700                             0      -2.603792                       0   \n",
       "16019                             0      -2.603792                       0   \n",
       "\n",
       "        total_of_special_requests  deposit_type_Non Refund     adr  \\\n",
       "14374                           0                        0  120.00   \n",
       "66734                           2                        0   97.02   \n",
       "7371                            0                        0  262.00   \n",
       "13898                           2                        0   33.00   \n",
       "8552                            0                        0   54.00   \n",
       "...                           ...                      ...     ...   \n",
       "86997                           0                        0   65.00   \n",
       "97719                           0                        0  102.68   \n",
       "112300                          0                        0  144.00   \n",
       "17700                           0                        0   58.00   \n",
       "16019                           2                        0  154.80   \n",
       "\n",
       "        cancelations_proportion  customer_type_Transient  country_PRT  \\\n",
       "14374                       0.5                        1            1   \n",
       "66734                       0.5                        1            0   \n",
       "7371                        0.5                        1            1   \n",
       "13898                       0.5                        1            1   \n",
       "8552                        0.5                        0            0   \n",
       "...                         ...                      ...          ...   \n",
       "86997                       0.0                        1            1   \n",
       "97719                       0.5                        1            0   \n",
       "112300                      0.5                        1            0   \n",
       "17700                       0.5                        1            0   \n",
       "16019                       0.5                        1            0   \n",
       "\n",
       "        previous_cancellations  previous_bookings_not_canceled  \\\n",
       "14374                        1                               0   \n",
       "66734                        0                               0   \n",
       "7371                         0                               0   \n",
       "13898                        1                               4   \n",
       "8552                         0                               0   \n",
       "...                        ...                             ...   \n",
       "86997                        0                               6   \n",
       "97719                        0                               0   \n",
       "112300                       0                               0   \n",
       "17700                        0                               0   \n",
       "16019                        0                               0   \n",
       "\n",
       "        hotel_Resort Hotel  country_GBR  country_FRA market_segment  \n",
       "14374                    1            0            0         Direct  \n",
       "66734                    0            0            0      Online TA  \n",
       "7371                     1            0            0      Online TA  \n",
       "13898                    1            0            0      Corporate  \n",
       "8552                     1            0            0         Groups  \n",
       "...                    ...          ...          ...            ...  \n",
       "86997                    0            0            0      Corporate  \n",
       "97719                    0            0            0  Offline TA/TO  \n",
       "112300                   0            0            0      Online TA  \n",
       "17700                    1            1            0         Groups  \n",
       "16019                    1            0            0      Online TA  \n",
       "\n",
       "[52437 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, X_train_val, y_train_val, X_test, y_test = create_sets(df, 1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stworzenie zmiennej przy wykorzystaniu Target Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['required_car_parking_spaces', 'lead_time_std',\n",
      "       'is_reserved_compatible', 'total_of_special_requests',\n",
      "       'deposit_type_Non Refund', 'adr', 'cancelations_proportion',\n",
      "       'customer_type_Transient', 'country_PRT', 'previous_cancellations',\n",
      "       'previous_bookings_not_canceled', 'hotel_Resort Hotel', 'country_GBR',\n",
      "       'country_FRA', 'market_segment', 'is_canceled'],\n",
      "      dtype='object')\n",
      "Index(['required_car_parking_spaces', 'lead_time_std',\n",
      "       'is_reserved_compatible', 'total_of_special_requests',\n",
      "       'deposit_type_Non Refund', 'adr', 'cancelations_proportion',\n",
      "       'customer_type_Transient', 'country_PRT', 'previous_cancellations',\n",
      "       'previous_bookings_not_canceled', 'hotel_Resort Hotel', 'country_GBR',\n",
      "       'country_FRA', 'market_segment', 'is_canceled'],\n",
      "      dtype='object')\n",
      "Index(['required_car_parking_spaces', 'lead_time_std',\n",
      "       'is_reserved_compatible', 'total_of_special_requests',\n",
      "       'deposit_type_Non Refund', 'adr', 'cancelations_proportion',\n",
      "       'customer_type_Transient', 'country_PRT', 'previous_cancellations',\n",
      "       'previous_bookings_not_canceled', 'hotel_Resort Hotel', 'country_GBR',\n",
      "       'country_FRA', 'market_segment', 'is_canceled'],\n",
      "      dtype='object')\n",
      "Index(['required_car_parking_spaces', 'lead_time_std',\n",
      "       'is_reserved_compatible', 'total_of_special_requests',\n",
      "       'deposit_type_Non Refund', 'adr', 'cancelations_proportion',\n",
      "       'customer_type_Transient', 'country_PRT', 'previous_cancellations',\n",
      "       'previous_bookings_not_canceled', 'hotel_Resort Hotel', 'country_GBR',\n",
      "       'country_FRA', 'market_segment', 'is_canceled'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_y_train = X_train.copy()\n",
    "X_y_train['is_canceled'] = y_train\n",
    "X_y_val = X_val.copy()\n",
    "X_y_val['is_canceled'] = y_val\n",
    "X_y_test = X_test.copy()\n",
    "X_y_test['is_canceled'] = y_test\n",
    "X_y_train_val = X_train_val.copy()\n",
    "X_y_train_val['is_canceled'] = y_train_val\n",
    "\n",
    "X_y_variables = [X_y_train, X_y_val, X_y_test, X_y_train_val]\n",
    "for X_y in X_y_variables:\n",
    "    print(X_y.columns)\n",
    "    target_means = X_y.groupby('market_segment')['is_canceled'].mean()\n",
    "    X_y['market_encoded'] = X_y['market_segment'].map(target_means)\n",
    "    X_y.drop(['market_segment'], axis=1, inplace=True)\n",
    "\n",
    "y_train, X_train = X_y_train['is_canceled'], X_y_train.drop('is_canceled', axis = 1)\n",
    "y_val, X_val = X_y_val['is_canceled'], X_y_val.drop('is_canceled', axis = 1)\n",
    "y_test, X_test = X_y_test['is_canceled'], X_y_test.drop('is_canceled', axis = 1)\n",
    "y_train_val, X_train_val = X_y_train_val['is_canceled'], X_y_train_val.drop('is_canceled', axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funkcje pomocnicze do tworzenia i ewalucacji modeli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_metrics(metrics, y_val_hat, _y_val = y_val , y_train = None, y_hat_train = None):\n",
    "      for metric in metrics:\n",
    "        print(metric + \":\")\n",
    "        # print(\"Zestaw treningowy:\")\n",
    "        # print(metrics[metric](y_train, y_hat_train))\n",
    "        # print(\"Zestaw walidacyjny:\")\n",
    "        print(metrics[metric](_y_val, y_val_hat))\n",
    "\n",
    "def modeling(model, method = None, src = 'accuracy', cv = None, x_train = X_train, _y_train = y_train, x_val = X_val, _y_val = y_val, return_clf = False, **kwargs):\n",
    "    clf = model(**kwargs)\n",
    "    if method == \"grid\":\n",
    "        clf = GridSearchCV(clf, param_grid, cv=cv, scoring=src) #, n_jobs=-1)\n",
    "    elif method == \"random\":\n",
    "        clf = RandomizedSearchCV(clf, param_distributions=param_grid, cv=cv, scoring=src, n_iter=10) #,n_jobs=-1)\n",
    "    if method is not None:\n",
    "        clf = clf.best_estimator_\n",
    "    clf.fit(x_train, _y_train, eval_set=[(x_val, _y_val)]) if model == xgb.XGBClassifier else clf.fit(x_train, _y_train)\n",
    "    y_hat = clf.predict(x_val)\n",
    "    #y_hat_train = clf.predict(x_train)\n",
    "    #y_prob = clf.predict_proba(x_val)[:, 1]\n",
    "    metrics = {\n",
    "        'f1': f1_score,\n",
    "        'accuracy': accuracy_score,\n",
    "        'precision': precision_score,\n",
    "        'recall': recall_score,\n",
    "        'roc_auc': roc_auc_score\n",
    "    }\n",
    "    disp_metrics(metrics, y_hat)\n",
    "\n",
    "    if return_clf: return metrics, y_hat, clf\n",
    "    return metrics, y_hat\n",
    "\n",
    "def optimise(model, space, metric = accuracy_score):\n",
    "    def objective(params):\n",
    "        clf = model(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        res = metric(y_val, y_pred)\n",
    "        return {'loss': -res, 'status': STATUS_OK}\n",
    "\n",
    "    best_params = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n",
    "    print(\"Best set of hyperparameters: \", best_params)\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele\n",
    "- zmienna objaśniana is_canceled, po m.in. usunięciu duplikatów z ramki, w wykorzystywanej ramce ma ok 72% zer i ok 28% jedynek\n",
    "- strojenie hiperparametrów jest przedstawione w bardziej (np poprzez komórki z wywołanie hyperopt i zapisanymi najlepszymi parametrami) lub mniej (np w sytuacjach gdy dobierano je bardziej \"ręcznie) jawny sposób"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresja logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5742694313083545\n",
      "accuracy:\n",
      "0.799141876430206\n",
      "precision:\n",
      "0.6879721092388147\n",
      "recall:\n",
      "0.49281997918834547\n",
      "roc_auc:\n",
      "0.7040431256888473\n"
     ]
    }
   ],
   "source": [
    "modeling(LogisticRegression, max_iter=100000, solver='newton-cholesky')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zwykłe drzewa\n",
    "- raczej zbyt proste i nieskuteczne modele dla tego problemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5908379421892935\n",
      "accuracy:\n",
      "0.7756864988558353\n",
      "precision:\n",
      "0.5925073252406865\n",
      "recall:\n",
      "0.5891779396462019\n",
      "roc_auc:\n",
      "0.7177842360952903\n"
     ]
    }
   ],
   "source": [
    "modeling(DecisionTreeClassifier) # dla criterion = \"entropy\" identyczne wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.612205772712749\n",
      "accuracy:\n",
      "0.7917048054919908\n",
      "precision:\n",
      "0.6269633507853403\n",
      "recall:\n",
      "0.5981269510926118\n",
      "roc_auc:\n",
      "0.7316078542445308\n"
     ]
    }
   ],
   "source": [
    "modeling(ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6253263707571801\n",
      "accuracy:\n",
      "0.802974828375286\n",
      "precision:\n",
      "0.6551173922954183\n",
      "recall:\n",
      "0.5981269510926118\n",
      "roc_auc:\n",
      "0.7393790574003494\n"
     ]
    }
   ],
   "source": [
    "modeling(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drzewa Gradient Boosting\n",
    "- zwracanie bardzo obiecujących wyników"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:08<00:00,  3.69s/trial, best loss: -0.7763157894736842]\n",
      "Best set of hyperparameters:  {'learning_rate': np.float64(0.3100696163412409), 'max_depth': np.float64(2.0), 'n_estimators': np.float64(557.0)}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 0, 8, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -0.5),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 700, 1))\n",
    "}\n",
    "optimise(xgb.XGBClassifier, space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6462408140192198\n",
      "accuracy:\n",
      "0.8209954233409611\n",
      "precision:\n",
      "0.7074257425742574\n",
      "recall:\n",
      "0.5947970863683663\n",
      "roc_auc:\n",
      "0.750771324249272\n"
     ]
    }
   ],
   "source": [
    "metrics, y_hat = modeling(xgb.XGBClassifier, tree_method=\"exact\", early_stopping_rounds=100, learning_rate = 0.3100696163412409, n_estimators = 557, max_depth = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6208983011403305\n",
      "accuracy:\n",
      "0.8136155606407323\n",
      "precision:\n",
      "0.7041435735022433\n",
      "recall:\n",
      "0.5552549427679501\n",
      "roc_auc:\n",
      "0.7334065640861447\n"
     ]
    }
   ],
   "source": [
    "metrics, y_hat = modeling(GradientBoostingClassifier)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6506564919762092\n",
      "accuracy:\n",
      "0.8219107551487415\n",
      "precision:\n",
      "0.7060399415489528\n",
      "recall:\n",
      "0.6033298647242455\n",
      "roc_auc:\n",
      "0.754051520133326\n"
     ]
    }
   ],
   "source": [
    "modeling(HistGradientBoostingClassifier, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testowanie dla różnych konfiguracji space i różnych loss function** - otrzymywanie różnych zestawów optymalnych hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:39<00:00,  1.60s/trial, best loss: -0.8237986270022883]\n",
      "Best set of hyperparameters:  {'class_weight': np.int64(1), 'l2_regularization': np.float64(0.13258194641807666), 'learning_rate': np.float64(0.0627604096823675), 'max_depth': np.float64(27.0), 'max_iter': np.float64(472.0), 'min_samples_leaf': np.float64(14.0)}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', ['balanced', None]),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)),\n",
    "    'l2_regularization': hp.loguniform('l2_regularization', -15, -0.5),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.005, 0.5),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 3, 20, 1)),\n",
    "    'max_iter' : scope.int(hp.quniform('max_iter', 100, 500, 1))\n",
    "}\n",
    "best_params = optimise(HistGradientBoostingClassifier, space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': np.int64(0),\n",
       " 'l2_regularization': np.float64(0.0006269644876478571),\n",
       " 'learning_rate': np.float64(0.05793385109728729),\n",
       " 'max_depth': np.float64(35.0),\n",
       " 'max_iter': np.float64(255.0),\n",
       " 'min_samples_leaf': np.float64(14.0)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # 'class_weight': hp.choice('class_weight', ['balanced', None]),\n",
    "    # 'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)),\n",
    "    # 'l2_regularization': hp.loguniform('l2_regularization', -10, -0.5),\n",
    "    # 'learning_rate': hp.uniform('learning_rate', 0.005, 0.5),\n",
    "    # 'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 3, 20, 1)),\n",
    "    # 'max_iter' : scope.int(hp.quniform('max_iter', 100, 500, 1))\n",
    "best_params # roc_auc best loss: -0.7946477104101374\n",
    "#{'class_weight': np.int64(0), 'l2_regularization': np.float64(0.0006269644876478571), 'learning_rate': np.float64(0.05793385109728729), 'max_depth': np.float64(35.0), 'max_iter': np.float64(255.0), 'min_samples_leaf': np.float64(14.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6495515695067264\n",
      "accuracy:\n",
      "0.8211670480549199\n",
      "precision:\n",
      "0.7040097205346294\n",
      "recall:\n",
      "0.6029136316337149\n",
      "roc_auc:\n",
      "0.753409478538751\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(best_params)\n",
    "metrics, y_hat = modeling(HistGradientBoostingClassifier, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l2_regularization': np.float64(0.2624932565184252),\n",
       " 'learning_rate': np.float64(0.20598295811552644),\n",
       " 'max_depth': np.float64(37.0),\n",
       " 'max_iter': np.float64(170.0),\n",
       " 'min_samples_leaf': np.float64(13.0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # 'class_weight': 'balanced',\n",
    "    # 'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)),\n",
    "    # 'l2_regularization': hp.loguniform('l2_regularization', -10, -0.5),\n",
    "    # 'learning_rate': hp.uniform('learning_rate', 0.005, 0.3),\n",
    "    # 'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 3, 20, 1)),\n",
    "    # 'max_iter' : scope.int(hp.quniform('max_iter', 100, 500, 1))\n",
    "best_params # f1 best loss: -0.6739334071361662\n",
    "#{'l2_regularization': np.float64(0.2624932565184252), 'learning_rate': np.float64(0.20598295811552644), 'max_depth': np.float64(37.0), 'max_iter': np.float64(170.0), 'min_samples_leaf': np.float64(13.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6484418944763191\n",
      "accuracy:\n",
      "0.8212242562929062\n",
      "precision:\n",
      "0.7056807051909892\n",
      "recall:\n",
      "0.5997918834547347\n",
      "roc_auc:\n",
      "0.7524797681573476\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(best_params)\n",
    "metrics, y_hat = modeling(HistGradientBoostingClassifier, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': np.int64(1),\n",
       " 'l2_regularization': np.float64(0.13258194641807666),\n",
       " 'learning_rate': np.float64(0.0627604096823675),\n",
       " 'max_depth': np.float64(27.0),\n",
       " 'max_iter': np.float64(472.0),\n",
       " 'min_samples_leaf': np.float64(14.0)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'class_weight': hp.choice('class_weight', ['balanced', None]),\n",
    "#     'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)),\n",
    "#     'l2_regularization': hp.loguniform('l2_regularization', -15, -0.5),\n",
    "#     'learning_rate': hp.uniform('learning_rate', 0.005, 0.5),\n",
    "#     'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 3, 20, 1)),\n",
    "#     'max_iter' : scope.int(hp.quniform('max_iter', 100, 500, 1))\n",
    "best_params # acc -0.8237986270022883\n",
    "#{'class_weight': np.int64(1), 'l2_regularization': np.float64(0.13258194641807666), 'learning_rate': np.float64(0.0627604096823675), 'max_depth': np.float64(27.0), 'max_iter': np.float64(472.0), 'min_samples_leaf': np.float64(14.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6501965188096575\n",
      "accuracy:\n",
      "0.8217963386727689\n",
      "precision:\n",
      "0.7060975609756097\n",
      "recall:\n",
      "0.6024973985431842\n",
      "roc_auc:\n",
      "0.7537141825063061\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(best_params)\n",
    "metrics, y_hat = modeling(HistGradientBoostingClassifier, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6532357906584131\n",
      "accuracy:\n",
      "0.8237414187643021\n",
      "precision:\n",
      "0.7112745098039216\n",
      "recall:\n",
      "0.6039542143600416\n",
      "roc_auc:\n",
      "0.7555076791721312\n"
     ]
    }
   ],
   "source": [
    "best_params = {'l2_regularization': np.float64(0.13258194641807666),\n",
    " 'learning_rate': np.float64(0.0627604096823675),\n",
    " 'max_depth': 27,\n",
    " 'max_iter': 472,\n",
    " 'min_samples_leaf': 14}\n",
    "metrics, y_hat = modeling(HistGradientBoostingClassifier, verbose = 2, **best_params)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost, naive bayes\n",
    "- wyniki znacznie poniżej oczekiwań"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5612855007473841\n",
      "accuracy:\n",
      "0.798512585812357\n",
      "precision:\n",
      "0.6990381632019858\n",
      "recall:\n",
      "0.4688865764828304\n",
      "roc_auc:\n",
      "0.6961789884386539\n"
     ]
    }
   ],
   "source": [
    "modeling(AdaBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5340634005763689\n",
      "accuracy:\n",
      "0.5375286041189932\n",
      "precision:\n",
      "0.36931048226385016\n",
      "recall:\n",
      "0.96420395421436\n",
      "roc_auc:\n",
      "0.6699915234582648\n"
     ]
    }
   ],
   "source": [
    "modeling(GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "- czasochłonne i dające słabe wyniki modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6153171907527117\n",
      "accuracy:\n",
      "0.799141876430206\n",
      "precision:\n",
      "0.6496992133271634\n",
      "recall:\n",
      "0.5843912591050988\n",
      "roc_auc:\n",
      "0.7324717636748374\n"
     ]
    }
   ],
   "source": [
    "modeling(SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5575561902396622\n",
      "accuracy:\n",
      "0.7961670480549199\n",
      "precision:\n",
      "0.6911945812807881\n",
      "recall:\n",
      "0.4672216441207076\n",
      "roc_auc:\n",
      "0.6940447471096635\n"
     ]
    }
   ],
   "source": [
    "metrics, y_hat = modeling(LinearSVC, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5727941176470588\n",
      "accuracy:\n",
      "0.8005720823798627\n",
      "precision:\n",
      "0.6965722801788375\n",
      "recall:\n",
      "0.48636836628511965\n",
      "roc_auc:\n",
      "0.7030263922155381\n"
     ]
    }
   ],
   "source": [
    "metrics, y_hat = modeling(SVC, kernel = 'linear', verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5549923973644196\n",
      "accuracy:\n",
      "0.7990846681922197\n",
      "precision:\n",
      "0.7094266277939747\n",
      "recall:\n",
      "0.4557752341311134\n",
      "roc_auc:\n",
      "0.6925030016809414\n"
     ]
    }
   ],
   "source": [
    "metrics, y_hat = modeling(NuSVC, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network - Multi-layer Perceptron\n",
    "- zwracanie dobrych wyników, aczkolwiek bez efektu \"wow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.656127204605684\n",
      "accuracy:\n",
      "0.7847254004576659\n",
      "precision:\n",
      "0.5848810687520365\n",
      "recall:\n",
      "0.7471383975026015\n",
      "roc_auc:\n",
      "0.7730563782384802\n"
     ]
    }
   ],
   "source": [
    "metrics, y_hat = modeling(MLPClassifier, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testowanie dla różnych konfiguracji space i różnych loss function** - otrzymywanie różnych zestawów optymalnych hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [42:10<00:00, 25.30s/trial, best loss: -0.7534324247219468] \n",
      "Best set of hyperparameters:  {'alpha': np.float64(0.020378920097890663)}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'alpha': hp.uniform('alpha', 0.000005, 0.03),\n",
    "    'hidden_layer_sizes': (50,100,50),\n",
    "    'early_stopping': True\n",
    "}\n",
    "best_params = optimise(MLPClassifier, space, metric=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': np.float64(0.020378920097890663)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'alpha': hp.uniform('alpha', 0.000005, 0.03),\n",
    "# 'hidden_layer_sizes': (50,100,50),\n",
    "# 'early_stopping': True\n",
    "best_params #roc_auc best loss: -0.7534324247219468\n",
    "#{'alpha': np.float64(0.020378920097890663)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5748518423086834\n",
      "accuracy:\n",
      "0.8112128146453089\n",
      "precision:\n",
      "0.7544808927967535\n",
      "recall:\n",
      "0.4643080124869927\n",
      "roc_auc:\n",
      "0.7035149529890585\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(best_params)\n",
    "metrics, y_hat = modeling(MLPClassifier, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': np.int64(0),\n",
       " 'alpha': np.float64(0.004461189588224096),\n",
       " 'hidden_layer_sizes': np.int64(1)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [(50,50,50), (50,100,50), (100,), (100,100,100)]),\n",
    "# 'activation': hp.choice('activation', ['relu', 'tanh']),\n",
    "# 'alpha': hp.uniform('alpha', 0.00005, 0.01)\n",
    "best_params #f1 best loss: -0.6592569723165586\n",
    "#{'activation': np.int64(0),\n",
    "#  'alpha': np.float64(0.004461189588224096),\n",
    "#  'hidden_layer_sizes': np.int64(1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6062226543509966\n",
      "accuracy:\n",
      "0.8146453089244852\n",
      "precision:\n",
      "0.7286006427110722\n",
      "recall:\n",
      "0.5190426638917794\n",
      "roc_auc:\n",
      "0.7228743891451007\n"
     ]
    }
   ],
   "source": [
    "# clf = MLPClassifier(best_params)\n",
    "# metrics, y_hat = modeling(MLPClassifier, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': np.int64(0),\n",
       " 'alpha': np.float64(0.0018514177742853834),\n",
       " 'hidden_layer_sizes': np.int64(1),\n",
       " 'learning_rate': np.int64(0),\n",
       " 'solver': np.int64(0)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [(50,), (50,100,50), (150,), (10,30,10)]),\n",
    "#     'activation': hp.choice('activation', ['relu', 'tanh']),\n",
    "#     'solver': hp.choice('solver', ['adam', 'sgd', 'lbfgs']),\n",
    "#     'learning_rate': hp.choice('learning_rate', ['constant','adaptive']),\n",
    "#     'alpha': hp.uniform('alpha', 0.0001, 0.5)\n",
    "best_params # accuracy best loss -0.8152173913043478\n",
    "#{'activation': np.int64(0),\n",
    "#  'alpha': np.float64(0.0018514177742853834),\n",
    "#  'hidden_layer_sizes': np.int64(1),\n",
    "#  'learning_rate': np.int64(0),\n",
    "#  'solver': np.int64(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6438809261300992\n",
      "accuracy:\n",
      "0.8152173913043478\n",
      "precision:\n",
      "0.6846424384525205\n",
      "recall:\n",
      "0.6077003121748179\n",
      "roc_auc:\n",
      "0.7507929568763636\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(best_params)\n",
    "metrics, y_hat = modeling(MLPClassifier, verbose = 2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier\n",
    "- wysoce skomplikowany model zawierający wewnątrz niektóre z wcześniej testowanych klasyfikatorów\n",
    "- dobre wyniki, jednak brak poprawy względem najlepszych z wcześniej testowanych modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level0 = list()\n",
    "level0.append(('lr', LogisticRegression(max_iter=100000, solver='newton-cholesky')))\n",
    "level0.append(('rf', RandomForestClassifier(n_estimators=1000,\n",
    "                                    max_depth=2,\n",
    "                                    min_samples_split = 2,\n",
    "                                    max_features = 3)))\n",
    "level0.append(('mlp1', MLPClassifier()))\n",
    "best_par = {'l2_regularization': np.float64(0.13258194641807666),\n",
    " 'learning_rate': np.float64(0.0627604096823675),\n",
    " 'max_depth': 27,\n",
    " 'max_iter': 472,\n",
    " 'min_samples_leaf': 14}\n",
    "level0.append(('hboost1', HistGradientBoostingClassifier(**best_par)))\n",
    "level0.append(('gboost', GradientBoostingClassifier()))\n",
    "level0.append(('xgb', xgb.XGBClassifier(tree_method=\"exact\",\n",
    "                                        learning_rate = 0.3100696163412409, \n",
    "                                        n_estimators = 557, max_depth = 2\n",
    "                    )))\n",
    "level0.append(('mlp2', MLPClassifier(alpha = np.float64(0.0018514177742853834), \n",
    "                                     hidden_layer_sizes = (50,100,50))))\n",
    "best_par = {'class_weight': 'balanced',\n",
    " 'l2_regularization': np.float64(0.0006269644876478571),\n",
    " 'learning_rate': np.float64(0.05793385109728729),\n",
    " 'max_depth': 35,\n",
    " 'max_iter': 255,\n",
    " 'min_samples_leaf': 14}\n",
    "level0.append(('hboost2', HistGradientBoostingClassifier(**best_par)))\n",
    "\n",
    "level1 = LogisticRegression(max_iter=100000, solver='newton-cholesky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6600175361683472\n",
      "accuracy:\n",
      "0.8225400457665903\n",
      "precision:\n",
      "0.6971521185459597\n",
      "recall:\n",
      "0.6266389177939646\n",
      "roc_auc:\n",
      "0.7617218257608876\n"
     ]
    }
   ],
   "source": [
    "metrics, y_hat = modeling(StackingClassifier, estimators=level0, final_estimator=level1, cv=5, verbose=2)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przykłady zastosowania walidacji krzyżowej z algorytmami grid search i random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52437, 15) (17480, 15) (17479, 15)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, X_train_val, y_train_val, X_test, y_test = create_sets(df, 1)\n",
    "def CrossValidateGrid(model, param_grid, random = False):\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    if not random:\n",
    "        grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy')\n",
    "        grid.fit(X_train_val, y_train_val)\n",
    "        print(grid.best_params_)\n",
    "        print(grid.best_score_)\n",
    "    else:\n",
    "        rand = RandomizedSearchCV(model, param_grid, cv=cv, scoring = 'accuracy')\n",
    "        rand.fit(X_train_val, y_train_val)\n",
    "        print(rand.best_score_)\n",
    "        print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossValidateGrid(DecisionTreeClassifier(), param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 2} \\\n",
    "0.8153667052964444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6294037940379403\n",
      "accuracy:\n",
      "0.8122425629290618\n",
      "precision:\n",
      "0.6879782769686498\n",
      "recall:\n",
      "0.5800208116545266\n",
      "roc_auc:\n",
      "0.7401484728884072\n"
     ]
    }
   ],
   "source": [
    "modeling(DecisionTreeClassifier, criterion = 'gini', max_depth = 10, max_features = None, min_samples_leaf = 4, min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossValidateGrid(LogisticRegression(), param_grid = {\n",
    "    'penalty': ['l1', 'l2', None],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'newton-cholesky'],\n",
    "    'l1_ratio': [0, 0.5, 1],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}, random= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.799390590912044 \\\n",
    "{'solver': 'newton-cholesky', 'penalty': None, 'max_iter': 1000, 'l1_ratio': 1, 'C': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.5756805807622505\n",
      "accuracy:\n",
      "0.799370709382151\n",
      "precision:\n",
      "0.6875722543352601\n",
      "recall:\n",
      "0.4951092611862643\n",
      "roc_auc:\n",
      "0.7049116325655187\n"
     ]
    }
   ],
   "source": [
    "modeling(LogisticRegression, solver = 'newton-cholesky', penalty = None, max_iter = 1000, l1_ratio = 1, C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossValidateGrid(GradientBoostingClassifier(), param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}, random= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8214310505924896 \\\n",
    "{'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.6475014037057832\n",
      "accuracy:\n",
      "0.8204233409610984\n",
      "precision:\n",
      "0.703170731707317\n",
      "recall:\n",
      "0.6\n",
      "roc_auc:\n",
      "0.7519921104536489\n"
     ]
    }
   ],
   "source": [
    "metrics, y_hat = modeling(GradientBoostingClassifier, n_estimators = 100, max_depth = 5, learning_rate = 0.1)\n",
    "disp_metrics(metrics, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udało nam się podciągnąć zarówno accuracy na, którym był skoncentrowany algorytm, a także zarazem wzrosło f1. Z uwagi na spory koszt obliczeniowy i potrzebny czas wykonania algorytmu można było wykorzystać tylko 8 unikalnych zestawów hiperparametrów. Użyto random search dla przyspieszenia tego procesu. Ostatecznie jednak wybrany został HistGradientBoosting, który jest zarówno szybszy, jak i dawał lepsze wyniki przed strojeniem hiperparametrów. Dla nieograniczonych zasobów zwykły GradientBoosting może mieć jednak większy potencjał."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie:\n",
    "- rozważane metryki to f1_score, accuracy, precision, recall i roc_auc\n",
    "- najlepiej wypadły modele HistGradientBoostingClassifier, XGBoost, MLPClassifier (wszystkie z dostrojonymi hiperparametrami) oraz StackingClassifier\n",
    "- zdecydowaliśmy się na model HistGradientBoostingClassifier z hiperparametrami: {'l2_regularization': 0.13258194641807666,\n",
    " 'learning_rate': 0.0627604096823675, 'max_depth': 27, 'max_iter': 472, 'min_samples_leaf': 14}\n",
    "- jest on prostszy i mniej wymagający obliczeniowo niż StackingClassifier oraz daje nieznacznie, ale jednak lepsze wyniki niż modele XGBoost i MLPClassifier\n",
    " - Wyniki dla wybranego przez nas modelu: \\\n",
    "f1: \\\n",
    "0.6532357906584131 \\\n",
    "accuracy:\\\n",
    "0.8237414187643021\\\n",
    "precision:\\\n",
    "0.7112745098039216\\\n",
    "recall:\\\n",
    "0.6039542143600416\\\n",
    "roc_auc:\\\n",
    "0.7555076791721312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatek - model dla \"surowych\" danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_raw.drop_duplicates().drop(['agent', 'company', 'reservation_status', 'reservation_status_date'], axis = 1).dropna()\n",
    "df_all_en = pd.get_dummies(df_temp, columns= df_temp.select_dtypes(include=['object']).columns.to_list(), drop_first=True, dtype='int')\n",
    "X_train, X_val, y_train, y_val, X_train_val, y_train_val, X_test, y_test = create_sets(df_all_en, 1)\n",
    "clf = xgb.XGBClassifier(early_stopping_rounds=200, learning_rate = 0.10780119865397095, n_estimators = 900, max_depth = 8)\n",
    "clf.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "y_hat = clf.predict(X_val, iteration_range=(0, clf.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:\n",
      "0.7047366091190792\n",
      "accuracy:\n",
      "0.8465608465608465\n",
      "precision:\n",
      "0.7511205472988912\n",
      "recall:\n",
      "0.6637481759432979\n",
      "roc_auc:\n",
      "0.7899790836034495\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "        print(metric + \":\")\n",
    "        print(metrics[metric](y_val, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wnioski** \n",
    "- model dla \"surowych\" danych (zawierających kilkaset, zamiast kilkunastu kolumn) z dostrojonymi hiperparametrami osiąga niewiele lepsze wyniki niż wybrany przez nas model, a jest nieporównywalnie gorszy z punktu widzenia wykorzystywanych zasobów\n",
    "- wybrany przez nas model powinien być raczej uznany jako dobry, gdyż niewiele więcej można \"wycisnąć\" z tego zbioru danych"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scikit_intelex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
